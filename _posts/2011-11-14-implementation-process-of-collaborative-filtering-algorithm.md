--- 
layout: post
title: 协同过滤算法的基本思想及优缺点
tags: 
- "机器学习"
- "推荐系统"
- "协同过滤"
status: publish
type: post
published: true
---
协同算法的实现分为三步：收集用户对项目的评分、计算收集数据的最近邻居、产生推荐结果。

收集用户对项目的评分

根据用户对项目评分数据的来源可以将评分分为显式评分和隐式评分，显式评分是指用户显式的给项目选择一个评分，这种评分方式是用户提供最准确的描述用户偏好的方式，但是这种方式需要用户额外的工作，并且面临“冷启动”问题；隐式评分是指系统通过分析用户的行为来推断用户对项目的爱好，如利用用户在一个项目上花费的时间评价对该项目的偏好程度，这种方法的不足是具有不确定性；

m个用户对n个项目的评分可以用一个如下所示的m*n的评分矩阵来表示，其中U1、U2、……、Um为m个用户，I1、I2、……、In为n个商品，矩阵的每个值M(i,j)为用户Ui对项目Ij的评分：

image

计算收集数据的最近邻居

协同过滤的出发点是计算用户的最近邻居，因此就归结为计算两个用户或项目的相似度，从而可以得到用户或项目的相似度排序。计算相似的算法主要包括欧几里德距离（Euclidean Distance Score）、皮尔逊相关度（Person Correlation Coefficient）、余弦相似性（Cosine-based Similarity）、调整余弦相似性（Adjusted Cosine Similarity）、Jaccard系数等。各种相似度的计算方法各有所长，要根据具体的应用场景来选取一种或几种综合使用。前二者适用于时间序列这样的稠密数据或二维点，后三者适用于像文档这样的稀疏数据;

1） 欧几里德距离：它以经过人们一致评价的物品为坐标轴，然后将参与评价的人绘制到图上，并考察他们彼此间的距离远近，欧几里德距离的计算公式如下：

clip_image001

根据公式可知，计算两个用户相似度的前提就是两个用户有相同的评价项。下图所示的X轴、Y轴分别为商品A和商品B，而在第一象限偏好空间里则是每个人对商品A和商品B的评价：可以发现用户A和用户B的空间距离较短（评分较为接近），根据欧几里德距离的结论，偏好越相似的人，其在偏好空间的距离就越短。

image

2） 皮尔逊相关度：它是通过判断两组数据与某一直线拟合程度来判断相似度。下图为用户A和用户B对五个商品的评分，虚线为最佳拟合线，其绘制的原则是尽可能靠近所有的点，如果用户A和用户B对五个商品的评分完全相同，则最佳拟合线为一条45度的对角直线，并且会覆盖图中所有的点。

clip_image001[14]

image

采用皮尔逊方法可以修正“夸大分值 （grade inflation）”的情况，因为即使用户B总是倾向于给出比用户A更高的分数，但最终的直线仍然拟合度较高，这是因为他们两者有着相对近似的偏好。也就是说，如果某人总是倾向于给出比另一人更高的分数，而两者的分差又始终保持一致，则他们依然可能会存在很好的相关性。而此前提到过的欧几里德距离评价方法，会因为一个人的评价始终比另一个人更为“严格”（从而导致评价始终相对较低），而得出两者不相近的结论，即使他们的品位很相似也是如此。当然，这一行为是否是我们想要的结果，取决于具体的应用场景。

3）余弦相似性：对于像文档向量这样的具有相对较少非零属性的数据，如果统计0-0匹配，则大部分文档与其他大部分文档都是相似的（类似于Jaccard系数），同时还要考虑如何处理非二元向量，这时可以采用余弦相似度方法，该方法将两个用户表示为两个m维的用户空间向量，它们之间的相关性用两个向量的余弦来度量，余弦值越大，表示两个向量直接的相关性越大，反之则越小。具体公式如下，根据公式可知，它不考虑两个数据对象的量值，对于长度为1的向量，该度量可以通过简单的计算点积取得。

image

4）修正余弦相似性：用余弦相似性计算两个用户的相关性有一个较大的缺点是没有考虑评分的尺度问题，修正的余弦相似性可以减去用户对项目的平均评分来改善上述缺陷。具体公式如下：

image

5）Jaccard系数：对于对称的二元属性可以采用简单批评系数（SMC）来度量，其值为“值匹配的属性个数”与“属性个数”之比，即(f11+f00)/(f01+f10+f11+f00)；而对于非对称二元属性，考虑如果每个非对称的二元属性对应于商店的一种商品，则1表示该商品被购买，而0表示该商品未被购买。由于未被顾客购买的商品数远大于被其购买的商品数，因而像SMC这样的相似性度量将会判定所有的事务都是类似的，这就需要采用Jaccard系数进行度量，其定义为“匹配个数”与“不涉及0-0匹配的属性个数”之比，即f11/(f01+f10+f11)

产生推荐结果

有了最近邻集合，就可以对目标使用者的兴趣进行预测，产生推荐结果。依据推荐目的的不同进行不同形式的推荐， 较常见的推荐结果有Top-N推荐和关联推荐。
•Top-N 推荐，针对个体使用者产生，对每个人产生不一样的结果，例如：透过对用户A的最近邻用户进行统计，选择出现频率高且在A使用者的评分项目中不存在的，作为推荐结果。这和一般网站上见到的“最热门”列表是不同的。热门列表是基于全部数据集产生的，它对每个人都是一样的。 
•关联推荐，又称为基于关联规则的推荐，它是对最近邻使用者的记录进行关联规则(association rules)挖掘。与传统关联规则针对全部数据进行挖掘不同的是，此方法仅对最近邻用户的购买记录进行关联规则挖掘。它最突出的优点就是，可以帮助你发现你感兴趣的而以前却从来没有注意过的商品。在 Amazon 介绍书的详细信息的页面上，可以看到这种推荐的一个实际应用。 
