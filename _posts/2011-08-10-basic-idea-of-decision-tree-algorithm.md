--- 
layout: post
title: 决策树算法的基本思想
tags: 
- "机器学习"
- "决策树"
status: publish
type: post
published: true
---
理论上讲，对于给定的属性集，可以构造的决策树的数目可以达到指数级。尽管总有一些决策树比其他决策树更为准确，但是由于搜索空间是指数级的，因此试图找到最优的决策树在计算上并不可行。为了在合理的时间内找到有较高准确率的次最优决策树，往往需要采用贪心算法，在选择用于划分数据的属性时，采用一系列局部最优决策来构造决策树。

最早的决策树算法是由Hunt等人于1966年提出，Hunt算法是许多决策树算法的基础，包括ID3、C4.5和CART等，本文以Hunt算法为例介绍决策树算发的基本思想及决策树的一些设计问题。

早期的决策树算法：Hunt算法

Hunt算法通过将训练记录相继划分为较纯的子集，以递归方式建立决策树。设Dt是与结点t相关联的训练记录集，而y = { y1, y2, …, yc}为类标号，Hunt算法的递归定义如下：

1〉如果Dt中所有的记录都属于同一个类yt，则结点t是叶子结点，用yt标记；

2）如果Dt中包含多个类的记录，则选择一个属性测试条件，将记录划分为较小的子集。对于测试条件的每个输出，创建一个子女结点，并根据测试结果将Dt中的记录分布到子女结点中，然后对每个子女结点递归地调用该算法；

对于以上算法，如果属性值的每种组合都在训练集中出现，并且每种组合都具有唯一的类标号，则Hunt算法是有效的。但是但对于大多数的实际情况来讲，这一假设并不现实，因此，需要额外的条件来处理以下情况：

1〉在第二步，算法所创建的子女结点可能为空，即不存在与这些结点相关联的记录。如果没有一个训练记录包含与这样的结点相关联的属性组合，这种情形就有可能发生。这时，该结点成为叶子结点，类标号为其父结点所关联记录集中类别个数最多的类别；

2〉在第二步，如果与Dt相关联的所有记录都具有相同的属性值（类标号除外），则没有属性可用于进一步划分当前记录集，这时可以采用投票原则（少数服从多数）将当前结点强制为叶结点，其类标号为该结点所关联记录集中类别个数最多的类别；

决策树归纳的设计问题

由Hunt算法的基本思想，我们可以看到，决策树归纳的学习算法必须解决以下两个问题：

1〉如何分裂训练记录集？

树增长的每次递归都必须要选择一个属性测试条件，将记录划分为更小的子集。为了更好的进行记录分割，算法必须为不同类型的属性指定测试条件的方法，并且提供评估每个测试条件优劣的客观标准；

2〉如何停止分裂？

为了终止决策树的成长过程，一个可能的策略是分裂结点直到所有的记录都属于同一类，或者所有的记录都具有相同的属性值。尽管这这两个约束条件对于结束决策树成长是充分的，但是我们往往还需要其他的标准来提前停止树的生长过程；
