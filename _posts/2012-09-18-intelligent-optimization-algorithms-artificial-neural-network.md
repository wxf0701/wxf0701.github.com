--- 
layout: post
title: 智能优化算法：人工神经网络
tags: 
- "最优化"
- "人工神经网络"
status: publish
type: post
published: true
---
人工神经网络(Artificial Neural Network)模拟生物神经处理，它由大量的节点（或称“神经元”，或“单元”）通过某种拓扑结构相连接而成，每个节点代表一种特定的输出函数，称为<i>激励函数</i>（activation function）。每两个节点间的连接都代表一个对于通过该连接信号的加权值，称之为<i>权重</i>（weight），这相当于人工神经网络的记忆。网络的输出则依赖于网络的连接方式、权重和激励函数的不同而不同。

# 人工神经网络的基本原理

首先看人脑的内部结构和工作原理：

+ 大脑是由大量神经细胞或神经元组成的，每个神经元可看作是一个小的处理单元，这些神经元按某种方式连接起来，形成大脑内部的生理神经元网络。
+ 神经元网络中各神经元之间联结的强弱，按外部的激励信号做自适应变化，而每个神经元又随着所接收到的多个接收信号的综合大小而呈现兴奋（1）或抑制（0）状态。
+ 大脑的学习过程就是神经元之间连接强度随外部激励信息做自适应变化的过程，而大脑处理信息的结果则由神经元的状态表现出来。

人工神经网络就是根据对生物神经网络进行模拟而开发出的一种算法：

+ 假如我们现在只有一些输入和相应的输出，而对如何由输入得到输出的机理并不清楚，那么我们可以把输入与输出之间的未知过程看成是一个“网络”；
+ 通过不断地给这个网络输入和相应的输出来“训练”这个网络，网络根据输入和输出不断地调节自己的各节点之间的权值来满足输入和输出。
+ 这样，当训练结束后，我们给定一个输入，网络便会根据自己已调节好的权值计算出一个输出。

# 人工神经网络的分类

按网络连接的拓扑结构分类：

1. 层次型结构：将神经元按功能分成若干层，如输入层、中间层（隐藏层）和输出层，各层顺序相连。

    + 输入层：负责接收来自外界的输入信息，并传递给中间各隐层神经元；
    + 隐藏层：负责信息变换，根据信息变换能力的需要，隐藏层可以是一层或多层；
    + 输出层：负责向外界输出信息处理结果

2. 互连型网络结构：网络中任意两个节点之间都可能存在连接路径。

    按网络内部的信息流向分类：

    + 前馈型（Feedforword）网络：网络信息处理的方向是从输入层到各隐藏层再到输出层逐层进行。前馈网络中一层的输出是下一层的输入，信息的处理具有逐层传递进行的方向性，一般不存在反馈环路。因此这类网络很容易串联起来建立多层前馈网络。
    + 反馈型（Feedback）网络：在反馈网络中所有节点都具有信息处理功能，而且每个节点既可以从外界接收输入，同时又可以向外界输出。

# 人工神经网络的处理流程

1. 产生随机的权值进行初始化，并给定输入向量和目标输出；
2. 计算隐藏层、输出层各计算节点的输出；
3. 计算目标值和实际输出值的偏差；
4. 计算反向误差，并进行权值学习；
5. 是否满足学习结束条件，若不满足，转到第2步；

# 激励函数

当输入信号进入神经元时，它们的值将于它们对应的权重相乘，作为神经元的输入，神经元内有一个函数，叫做激励（Activation）函数，它把所有这些新的、经过权重调整后的输入全部加起来，形成单个的激励值(Activation Value)。激励值也是一浮点数，且同样可正可负。然后，再根据激励值来产生函数的输出也即神经细胞的输出：如果激励值超过某个阀值（作为例子我们假设阀值为1），就会产生一个值为1的信号输出；如果激励值小于阀值1，则输出一个0。这是人工神经细胞激励函数的一种最简单的类型。

常见的激励函数有阈值型函数（见图a，b），饱和型函数（见图c），双曲函数（见图d），S型函数（见图e），高斯函数（见图f）

![激励函数](/upload/pic/2012-09-18-ann.png "")
